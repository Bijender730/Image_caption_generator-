{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZvhjOc1Ul1k"
      },
      "outputs": [],
      "source": [
        "#  importing modules \n",
        "import os\n",
        "import pickle \n",
        "import numpy as np \n",
        "import nltk \n",
        "import tensorflow as tf\n",
        "from tqdm.notebook import tqdm\n",
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import load_img , img_to_array\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer \n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import to_categorical, plot_model\n",
        "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, add\n",
        "from PIL import Image\n",
        "from numpy import asarray\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How download Dataset\n",
        "1)First make an account on Kaggle. \n",
        "2) Login to your account\n",
        "3) First click on Three dots present on window then click on create an api. It will download a kaggle.json file \n",
        "4) Then make a folder in your drive named kaggle. Upload that Kaggle.json in that folder \n",
        "5) Then Type name of dataset in search option in kaggle account. \n",
        "6) Click on three dots of that dataset. Copy api\n",
        "7) use this \"!(paste copied api)\""
      ],
      "metadata": {
        "id": "P9whnBHy2QxO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "3rPqMwEzyAFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_t2lYEoblH28"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TeOLy4kirTkf"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/drive/MyDrive/Kaggle'\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/drive/MyDrive/Kaggle'"
      ],
      "metadata": {
        "id": "ulI8zBpOGwSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d adityajn105/flickr8k"
      ],
      "metadata": {
        "id": "MyI-_s5gHbZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # load VGG16 model\n",
        "model_1 = VGG16()\n",
        "# restructure the model\n",
        "model_1 = Model(inputs= model_1.inputs,outputs = model_1.layers[-2].output) #leaving the last layer that is prediction layer\n",
        "model_1.summary()"
      ],
      "metadata": {
        "id": "GCNQ4EvMH95I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "  \n",
        "# specifying the zip file name\n",
        "file_name = \"/content/drive/MyDrive/Kaggle/Flickr8k_image_caption_generator/flickr8k.zip\"\n",
        "  \n",
        "# opening the zip file in READ mode\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "    # printing all the contents of the zip file\n",
        "    zip.printdir()\n",
        "  \n",
        "    # extracting all the files\n",
        "    # print('Extracting all the files now...')\n",
        "    zip.extractall()\n",
        "    # print('Done!')"
      ],
      "metadata": {
        "id": "6IEZiZoKKxbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extraction features from image\n",
        "features = {}\n",
        "directory  = '/content/drive/MyDrive/Kaggle/Images'\n",
        "for img_name in tqdm(os.listdir(directory)):\n",
        "  img_path = directory + '/' + img_name # creating path to load image\n",
        "  image = load_img(img_path,target_size = (224,224)) # loading images\n",
        "  # converting images to numpy array\n",
        "  image = img_to_array(image)\n",
        "  # reshape data for model\n",
        "  image = image.reshape(1,image.shape[0],image.shape[1],image.shape[2])\n",
        "\n",
        "  # preprocessing image for VGG\n",
        "  image = preprocess_input(image)\n",
        "  # extract features\n",
        "  feature = model_1.predict(image,verbose = 0)\n",
        "  # get image ID\n",
        "  image_id = img_name.split('.')[0]\n",
        "\n",
        "  # storing features  \n",
        "  features[image_id] = feature\n",
        "\n"
      ],
      "metadata": {
        "id": "s7jnFltqIdKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features['973827791_467d83986e']"
      ],
      "metadata": {
        "id": "ECbKMdcLmvFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# store features in pickle \n",
        "pickle.dump(features, open(os.path.join('/content/drive/MyDrive/Kaggle','features.pkl'),'wb'))"
      ],
      "metadata": {
        "id": "BrDk2G2MQdu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load features from pickle \n",
        "with open(os.path.join('/content/drive/MyDrive/Kaggle','features.pkl'),'rb') as f:\n",
        "  features = pickle.load(f)"
      ],
      "metadata": {
        "id": "tCFOj8CvujHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features"
      ],
      "metadata": {
        "id": "dPhmFMb0j3ot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the captions data \n",
        "with open(('/content/drive/MyDrive/Kaggle/captions.txt'),'r') as f:\n",
        "  next(f)\n",
        "  captions_doc = f.read()\n"
      ],
      "metadata": {
        "id": "sAZDcvDhu1Ry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "captions_doc"
      ],
      "metadata": {
        "id": "-5g2f8WcxWpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create mapping of image to captions\n",
        "mapping = {}\n",
        "# processing image\n",
        "for line in tqdm(captions_doc.split('\\n')):\n",
        "  # split the line by comma()\n",
        "  tokens = list(line.split(','))\n",
        "  # print(tokens[0][1:])\n",
        "  if len(line) <2:\n",
        "    continue \n",
        "  image_id, caption = tokens[0], tokens[1:]\n",
        "\n",
        "  # removing extension from Image_id\n",
        "  image_id = image_id.split('.')[0]\n",
        "  # converting the caption list into string \n",
        "  caption = \" \".join(caption)\n",
        "  # print((image_id,caption))\n",
        "\n",
        "  # print(caption)\n",
        "  # creating list \n",
        "  if image_id not in mapping:\n",
        "    mapping[image_id] = []\n",
        "    # mapping[image_id].append(caption)\n",
        "    #  storing the caption\n",
        "  if image_id in mapping:\n",
        "    mapping[image_id].append(caption)"
      ],
      "metadata": {
        "id": "EZkkHnWtvX_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mapping"
      ],
      "metadata": {
        "id": "zHkd_EpnyCOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning \n",
        "def clean(mapping):\n",
        "  for key,captions in mapping.items():\n",
        "    for i in range(len(captions)):\n",
        "      # take one caption at a time \n",
        "      caption = captions[i]\n",
        "      # preprocessing steps\n",
        "      caption = caption.lower() \n",
        "      caption = caption.replace('[^A-Za-z',\"\") #removing special characters etc\n",
        "      caption = caption.replace('\\s+',\" \") #deleting additional spaces \n",
        "      caption = 'startseq ' + \" \".join([word for word in caption.split() if len(word)>1]) + ' endseq' #adding strting and ending in the caption \n",
        "      captions[i] = caption\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PlHvwEScyHkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# before preprocess of text \n",
        "mapping['1000268201_693b08cb0e']"
      ],
      "metadata": {
        "id": "Y6zIVQVy80gC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing the text \n",
        "clean(mapping)"
      ],
      "metadata": {
        "id": "6gHuAqv49IZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# after preprocessing the text \n",
        "mapping['1000268201_693b08cb0e']"
      ],
      "metadata": {
        "id": "osbL9ysZ-sWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_captions = []\n",
        "for key in mapping:\n",
        "  for caption in mapping[key]:\n",
        "    all_captions.append(caption)\n",
        "print(all_captions)"
      ],
      "metadata": {
        "id": "fwxSE8UT--NU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(all_captions)"
      ],
      "metadata": {
        "id": "MBX-5ipZ_g__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  tokenizing the text \n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(all_captions)\n",
        "print(tokenizer.fit_on_texts(all_captions))\n",
        "# for i in (tokenizer.word_index):\n",
        "print(all_captions)\n",
        "vocab_size = len(tokenizer.word_index) +1"
      ],
      "metadata": {
        "id": "cSg1IG_d_mTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(tokenizer.word_index))"
      ],
      "metadata": {
        "id": "mOVcgqjR0ut2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size"
      ],
      "metadata": {
        "id": "EuiP3ZSzAbD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get maximum length of the caption available \n",
        "max_length =  max(len(caption.split()) for caption in all_captions)\n",
        "max_length"
      ],
      "metadata": {
        "id": "B2BJwdDBAc-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train test split"
      ],
      "metadata": {
        "id": "ipIBV5syA95e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_ids = list(mapping.keys())\n",
        "split = int(len(image_ids) * 0.90)\n",
        "print(split)\n",
        "train = image_ids[:split]\n",
        "test =  image_ids[split:]"
      ],
      "metadata": {
        "id": "CiyejqryAwMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  creating data generator to get data in both(avoid session crashing)\n",
        "def data_generator(data_keys,mapping,features,tokenizer,max_length,vocab_size,batch_size):\n",
        "  # loop over images \n",
        "  X1,X2,y =  list(),list(),list()\n",
        "  n = 0\n",
        "  while 1:\n",
        "    for key in data_keys:\n",
        "      n += 1\n",
        "      captions = mapping[key]\n",
        "\n",
        "      #  processing each captions\n",
        "      for caption in captions:\n",
        "        # encode the Sequence \n",
        "        seq = tokenizer.texts_to_sequences([caption])[0]\n",
        "        # split the sequence into X,y pairs\n",
        "        for i in range(1, len(seq)):\n",
        "          # split into input and output pairs\n",
        "          in_seq, out_seq = seq[:i], seq[i]\n",
        "          # padd input sequence \n",
        "          in_seq = pad_sequences([in_seq],maxlen = max_length)[0]\n",
        "          # encode output sequence \n",
        "          out_seq = to_categorical([out_seq], num_classes = vocab_size)[0]\n",
        "\n",
        "          # store the sequence \n",
        "          # if key not in features:\n",
        "          #   continue\n",
        "          X1.append(features[key][0])\n",
        "          X2.append(in_seq)\n",
        "          y.append(out_seq)\n",
        "      if n == batch_size:\n",
        "        X1,X2,y = np.array(X1), np.array(X2), np.array(y)\n",
        "        yield[X1,X2], y \n",
        "        X1, X2,  y = list(),list(),list()\n",
        "        n=0\n",
        "        \n",
        "\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "Bp96kL9kA8cK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating model"
      ],
      "metadata": {
        "id": "Tn6YfjaWSiBV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# encoder model\n",
        "# image feature layers\n",
        "inputs1 = Input(shape =(4096,))\n",
        "fe1 = Dropout(0.4)(inputs1)\n",
        "fe2 = Dense(256,activation = 'relu')(fe1)\n",
        "# sequence feature layers \n",
        "inputs2 = Input(shape=(max_length,))\n",
        "se1 = Embedding(vocab_size,256,mask_zero = True)(inputs2)\n",
        "se2 = Dropout(0.4)(se1)\n",
        "se3 = LSTM(256)(se2)\n",
        "\n",
        "# decoder model \n",
        "decoder1 = add([fe2,se3])\n",
        "decoder2 = Dense(256, activation = 'relu')(decoder1)\n",
        "outputs = Dense(vocab_size,activation = 'softmax')(decoder2)\n",
        "\n",
        "model_2 = Model(inputs =[inputs1,inputs2], outputs = outputs)\n",
        "model_2.compile(loss = 'categorical_crossentropy', optimizer = 'adam')\n",
        "\n",
        "# plot the model \n",
        "plot_model(model_2,show_shapes=True)"
      ],
      "metadata": {
        "id": "61sgHDWZSf9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training the model \n",
        "epochs = 20\n",
        "batch_size = 32 \n",
        "steps = len(train) // batch_size\n",
        "for i in range(epochs):\n",
        "  generator = data_generator(train,mapping,features,tokenizer,max_length,vocab_size,batch_size)\n",
        "  # fit for one epoch\n",
        "  model_2.fit(generator, epochs = 1 , steps_per_epoch = steps,verbose=1)"
      ],
      "metadata": {
        "id": "Jw8WOmBsTXsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qa5CXMl49Bnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saving the model\n",
        "# model.save(Path of directory where you want to save the model'Img_cap_gen.h5')\n",
        "model_2.save('/content/drive/MyDrive/Kaggle/Flickr8k_image_caption_generator/Img_cap_gen.h5')\n",
        "# mapping[key]\n",
        "# print(X1)"
      ],
      "metadata": {
        "id": "dEJ7jAa69-XR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Captions for the image \n"
      ],
      "metadata": {
        "id": "VrGNN6DZFNJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py    \n",
        "import numpy as np    \n",
        "# f1 = h5py.File('/content/drive/MyDrive/Kaggle/Flickr8k_image_caption_generator/Img_cap_gen.h5','r+')\n",
        "model_3 = tf.keras.models.load_model('/content/drive/MyDrive/Kaggle/Flickr8k_image_caption_generator/Img_cap_gen.h5')"
      ],
      "metadata": {
        "id": "jhdVk88uUSUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def index_to_word(integer, tokenizer):\n",
        "  for word, index in tokenizer.word_index.items():\n",
        "    if index == integer:\n",
        "      return word\n",
        "  return None\n"
      ],
      "metadata": {
        "id": "kTGVxQUY-GXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for i in range(max_length):\n",
        "\n",
        "#   in_text = 'startseq'\n",
        "#     #  encode input Sequence\n",
        "#   sequence  = tokenizer.texts_to_sequences([in_text])[0]\n",
        "#     #  pad the sequence \n",
        "#   print(sequence)\n",
        "#   sequence = pad_sequences([sequence],max_length)\n",
        "#     # preidict next word\n",
        "#   yhat = model_2.predict([image,sequence],verbose =0)\n",
        "#     # get index with high probability \n",
        "#   yhat =  np.argmax(yhat)\n",
        "#     #convert index to word\n",
        "#   word = index_to_word(yhat,tokenizer)\n",
        "#   print(word)"
      ],
      "metadata": {
        "id": "f-jwyO4bGpbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate caption for the image \n",
        "def predict_caption(model,image,tokenizer, max_length):\n",
        "  # add start tag for geeneration process\n",
        "  in_text = 'startseq' \n",
        "  # iterate over the max_length of sequence\n",
        "\n",
        "  for i in range(max_length):\n",
        "    #  encode input Sequence\n",
        "    sequence  = tokenizer.texts_to_sequences([in_text])[0]\n",
        "    #  pad the sequence \n",
        "    # print(sequence)\n",
        "    sequence = pad_sequences([sequence],max_length)\n",
        "    # preidict next word\n",
        "    yhat = model.predict([image,sequence],verbose =0)\n",
        "    # get index with high probability \n",
        "    yhat =  np.argmax(yhat)\n",
        "    # print(yhat)\n",
        "    #convert index to word\n",
        "    word = index_to_word(yhat,tokenizer)\n",
        "    # print(word)\n",
        "    # stop is word not found \n",
        "    if word is None:\n",
        "      break\n",
        "      # append word as input for generating next word\n",
        "    in_text += \" \"+ word\n",
        "    # stop if we reach end tag \n",
        "    if word == 'endseq':\n",
        "      break\n",
        "  return in_text\n",
        "# y_pred = predict_caption(model_2, features[key], tokenizer, max_length)\n",
        "# print(y_pred)"
      ],
      "metadata": {
        "id": "MtR6LPeNFq-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "#  validate with test data \n",
        "actual, predicted = list(), list()\n",
        "for key in tqdm(test):\n",
        "  #  get actual caption \n",
        "  captions = mapping[key]\n",
        "  # predict the caption for range \n",
        "  y_pred = predict_caption(model_2, features[key], tokenizer, max_length)\n",
        "  actual_captions = [caption.split() for caption in captions]\n",
        "  y_pred = y_pred.split()\n",
        "  #  append to the list \n",
        "  actual.append(actual_captions)\n",
        "  predicted.append(y_pred)\n",
        "#  calculate BLEU score\n",
        "print('BLEU-1:%f' % corpus_bleu(actual,predicted, weights=(1,0,0,0,0)))\n",
        "print('BLEU-2:%f' % corpus_bleu(actual,predicted, weights=(0.5,0.5,0,0,0)))\n"
      ],
      "metadata": {
        "id": "gLTQyXWWHUKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize the result "
      ],
      "metadata": {
        "id": "LVq7953sX82P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio as iio\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "def generate_caption(image_name):\n",
        "    # load the image\n",
        "    # image_name = \"1001773457_577c3a7d70.jpg\"\n",
        "    image_id = image_name.split('.')[0]\n",
        "    # print(image_id)\n",
        "    img_path = os.path.join('/content/drive/MyDrive/Kaggle/Images', image_name)\n",
        "    # image_array = ()\n",
        "    image = Image.open(img_path)\n",
        "    # for i in image_array:\n",
        "    #   print(i)\n",
        "    #   # if i == image_name:\n",
        "    #     # image = i\n",
        "    \n",
        "\n",
        "    # # print(image)\n",
        "    # # plt.imshow(image)\n",
        "    captions = mapping[image_id]\n",
        "    print('---------------------Actual---------------------')\n",
        "    for caption in captions:\n",
        "        print(caption)\n",
        "    # predict the caption\n",
        "    y_pred = predict_caption(model_2, features[image_id], tokenizer, max_length)\n",
        "    # print(model_3)\n",
        "    print('--------------------Predicted--------------------')\n",
        "    print(y_pred)\n",
        "    plt.imshow(image)\n"
      ],
      "metadata": {
        "id": "_-vHjkCOIKzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(features['1001773457_577c3a7d70'])"
      ],
      "metadata": {
        "id": "bANsv-cNd_Pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_caption(\"1001773457_577c3a7d70.jpg\")"
      ],
      "metadata": {
        "id": "ho5zuZzHYgL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7R-stwuddAdb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "private_outputs": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}